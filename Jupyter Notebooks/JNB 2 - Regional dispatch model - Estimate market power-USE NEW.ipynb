{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a727d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T01:27:58.617859Z",
     "start_time": "2024-07-23T01:27:58.609930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffa408",
   "metadata": {},
   "source": [
    "<font color='red'>Note</font>\n",
    "- Split the non-storage and storage process\n",
    "    - For non-storage, use a monthly basis process\n",
    "    - For storage, can process all data in one go\n",
    "\n",
    "In future, the function for non-storage needs adjustmens:\n",
    "- Not about calculation, about path and fueltype filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dd5c1b-1317-4fd2-8389-bef966b39f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T01:28:00.044615Z",
     "start_time": "2024-07-23T01:28:00.040480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "file_path = '/Volumes/EnergyData/AER/'\n",
    "\n",
    "bid_dayoffer_path = f'{file_path}Raw_data_zipped/BIDDAYOFFER_D'\n",
    "bid_peroffer_path = f'{file_path}Raw_data_zipped/BIDPEROFFER_D'\n",
    "dispatch_load_path = f'{file_path}Raw_data_zipped/DISPATCHLOAD'\n",
    "dispatch_regionsum_path = f'{file_path}Raw_data_zipped/DISPATCHREGIONSUM'\n",
    "dispatch_price_path = f'{file_path}Raw_data_zipped/DISPATCHPRICE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b1c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get YearMonth to FY mapping dict\n",
    "YearMonthFY = pd.read_excel(f'{file_path}Reference_data/duidinfo_SRMC.xlsx',\n",
    "                         sheet_name='YearMonthFY').set_index(['Year','Month'])['FY'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cb25a",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff5ad3",
   "metadata": {},
   "source": [
    "## Read DUID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7fb045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:34:36.494590Z",
     "start_time": "2024-07-14T11:34:36.492438Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_regional_duid_mapping(file_path,regionid):\n",
    "    # Read the duid mapping table\n",
    "    # It is obtained from Brian (from AER database)\n",
    "    # Only SA1 DUIDs, covers both GENERATOR and LOAD\n",
    "    duid_mapping = pd.read_csv(f'{file_path}Reference_data/duidinfo.csv',\n",
    "                               usecols=['DUID','REGIONID','STATIONNAME','PARTICIPANTNAME',\n",
    "                                        'DISPATCHTYPE','SCHEDULE_TYPE','FUELTYPE'])\n",
    "    duid_mapping = duid_mapping[(duid_mapping['REGIONID']==regionid)&\n",
    "                                (duid_mapping['DISPATCHTYPE']=='GENERATOR')&\n",
    "                                (duid_mapping['SCHEDULE_TYPE'].isin(['SCHEDULED','SEMI-SCHEDULED']))]\n",
    "    return duid_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04beb947",
   "metadata": {},
   "source": [
    "## Read DISPATCHPRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa52cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:34:53.457123Z",
     "start_time": "2024-07-14T11:34:43.132218Z"
    }
   },
   "outputs": [],
   "source": [
    "# The dispatch price (ROP and RRP) are read as reference for calculating market power.\n",
    "dispatch_price = pd.DataFrame()\n",
    "for year in range(2017,2024):\n",
    "    for month in range(1,13):\n",
    "        try:\n",
    "            temp_price = pd.read_csv(f'{dispatch_price_path}/PUBLIC_DVD_DISPATCHPRICE_{str(year)}{str(month).zfill(2)}010000.zip',\n",
    "                                     skiprows=1,\n",
    "                                     usecols=['SETTLEMENTDATE','REGIONID','RRP','ROP',\n",
    "                                              'INTERVENTION','MARKETSUSPENDEDFLAG'],\n",
    "                                     parse_dates=['SETTLEMENTDATE']).dropna(subset=['REGIONID'])\n",
    "            temp_price = temp_price[(temp_price['REGIONID'].isin(['NSW1','QLD1','VIC1','SA1']))&\n",
    "                                    (temp_price['INTERVENTION']==0)].drop(columns=['INTERVENTION']).round(2)\n",
    "            dispatch_price = pd.concat([dispatch_price,temp_price])\n",
    "        except:\n",
    "            pass\n",
    "dispatch_price = dispatch_price.drop_duplicates(subset=['SETTLEMENTDATE','REGIONID'])\n",
    "dispatch_price = dispatch_price[(dispatch_price['SETTLEMENTDATE']>=datetime.datetime(2017,7,1,0,5,0))&\n",
    "                                (dispatch_price['SETTLEMENTDATE']<=datetime.datetime(2023,7,1,0,0,0))]\\\n",
    "                    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e319a06",
   "metadata": {},
   "source": [
    "# Regional collective market power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595be9ea",
   "metadata": {},
   "source": [
    "Read all regional collective data in one go as the data size is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882e502e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:35:11.264274Z",
     "start_time": "2024-07-14T11:35:11.258917Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_and_process_regional_collective_marketpower(regionid,dispatch_price):\n",
    "    temp_srmc_bid = pd.read_csv(f'/Volumes/EnergyData/AER/Lerner_Index/Regional_SRMC_Supply_Curve_{regionid}.csv',\n",
    "                                parse_dates=['SETTLEMENTDATE'],\n",
    "                                usecols=['SETTLEMENTDATE','FY','Year','Quarter','Month','Hour',\n",
    "                                         'REGIONID','RRP_simulated'])\\\n",
    "                        .rename(columns={'RRP_simulated':'P0'})\n",
    "    temp_actual_bid = pd.read_csv(f'/Volumes/EnergyData/AER/Lerner_Index/Regional_Actual_Supply_Curve_{regionid}.csv',\n",
    "                                  parse_dates=['SETTLEMENTDATE'],\n",
    "                                  usecols=['SETTLEMENTDATE','REGIONID','RRP_simulated','RegionalTarget']).rename(columns={'RRP_simulated':'P1'})\n",
    "    temp_df = temp_srmc_bid.merge(right=temp_actual_bid,\n",
    "                                  on=['REGIONID','SETTLEMENTDATE'],\n",
    "                                  how='left')\n",
    "    temp_df = temp_df.merge(right=dispatch_price,\n",
    "                            on=['REGIONID','SETTLEMENTDATE'],\n",
    "                            how='left')\n",
    "\n",
    "    temp_df = temp_df[['SETTLEMENTDATE','REGIONID',\n",
    "                       'FY','Year','Quarter','Month','Hour',\n",
    "                       'RegionalTarget',\n",
    "                       'P0','P1','ROP','RRP',\n",
    "                       'MARKETSUSPENDEDFLAG']]\n",
    "\n",
    "    temp_df['Cost_P0'] = temp_df['RegionalTarget']*temp_df['P0']/12\n",
    "    temp_df['Cost_P1'] = temp_df['RegionalTarget']*temp_df['P1']/12\n",
    "    temp_df['Cost_RRP'] = temp_df['RegionalTarget']*temp_df['RRP']/12\n",
    "\n",
    "    temp_df['MarketPower_Tentative'] = temp_df['Cost_P1']-temp_df['Cost_P0']\n",
    "    temp_df['MarketPower_Effective'] = temp_df['Cost_RRP']-temp_df['Cost_P0']\n",
    "\n",
    "    temp_df['MARKETSUSPENDEDFLAG'] = temp_df['MARKETSUSPENDEDFLAG'].fillna(0)\n",
    "    temp_df = temp_df[temp_df['MARKETSUSPENDEDFLAG']==0]\n",
    "    \n",
    "    temp_df_agg = temp_df.groupby(by=['REGIONID','FY','Year','Quarter','Month','Hour'],\n",
    "                                  as_index=False)\\\n",
    "                                    [['RegionalTarget','Cost_P0','Cost_P1','Cost_RRP',\n",
    "                                      'MarketPower_Tentative','MarketPower_Effective']].sum()\n",
    "    return temp_df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd6929",
   "metadata": {},
   "source": [
    "## Estimating regional collective market power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecb87e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:35:37.881262Z",
     "start_time": "2024-07-14T11:35:36.457783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA1\n"
     ]
    }
   ],
   "source": [
    "for regionid in ['SA1']:\n",
    "    print(regionid)\n",
    "    temp_df_agg = read_and_process_regional_collective_marketpower(regionid,dispatch_price)\n",
    "    temp_df_agg.to_csv(f'/Volumes/EnergyData/AER/Lerner_Index/Regional_collective_market_power_{regionid}.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57112772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:49:04.899050Z",
     "start_time": "2024-07-14T11:49:00.053609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSW1\n",
      "QLD1\n",
      "VIC1\n"
     ]
    }
   ],
   "source": [
    "for regionid in ['NSW1','QLD1','VIC1']:\n",
    "    print(regionid)\n",
    "    temp_df_agg = read_and_process_regional_collective_marketpower(regionid,dispatch_price)\n",
    "    temp_df_agg.to_csv(f'/Volumes/EnergyData/AER/Lerner_Index/Regional_collective_market_power_{regionid}.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4171ff9",
   "metadata": {},
   "source": [
    "# Regional individual market power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003a54c",
   "metadata": {},
   "source": [
    "Read and process individual market power data at a monthly basis to avoid crashing from RAM explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bd28c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:39:55.731502Z",
     "start_time": "2024-07-14T11:39:55.654663Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_and_process_individual_market_power(file_path,regionid,level,Year,Month):\n",
    "    \n",
    "#     # Read dispatch price data\n",
    "#     temp_price = pd.read_csv(f'{dispatch_price_path}/PUBLIC_DVD_DISPATCHPRICE_{str(Year)}{str(Month).zfill(2)}010000.zip',\n",
    "#                              skiprows=1,\n",
    "#                              usecols=['SETTLEMENTDATE','REGIONID','RRP',\n",
    "#                                       'INTERVENTION','MARKETSUSPENDEDFLAG'],\n",
    "#                              parse_dates=['SETTLEMENTDATE']).dropna(subset=['REGIONID'])\n",
    "#     temp_price = temp_price[(temp_price['REGIONID']==regionid)&\n",
    "#                             (temp_price['INTERVENTION']==0)].drop(columns=['INTERVENTION']).round(2)\n",
    "    \n",
    "    # Read regional duid mapping\n",
    "    duid_mapping = get_regional_duid_mapping(file_path,regionid)[['DUID','FUELTYPE','STATIONNAME','PARTICIPANTNAME']]\n",
    "    \n",
    "    if level == 'STATIONNAME':\n",
    "        duid_mapping = duid_mapping[['STATIONNAME','PARTICIPANTNAME','FUELTYPE']]\\\n",
    "                            .drop_duplicates(subset=['STATIONNAME','PARTICIPANTNAME'])\n",
    "    \n",
    "    # Read the individual market power data, filter by the specified Year and Month\n",
    "    temp_actual_bid_individual = pd.read_csv(f'{file_path}Lerner_Index/Regional_ACTUAL_Supply_Curve_{regionid}_{level}.csv',\n",
    "                                         parse_dates=['SETTLEMENTDATE'])\\\n",
    "                                .drop(columns=['TOTALDEMAND','NETINTERCHANGE','FIXEDLOAD','DISPATCHABLELOAD'])\\\n",
    "                                .rename(columns={'RRP_simulated':'P1'})\n",
    "    temp_actual_bid_individual = temp_actual_bid_individual[(temp_actual_bid_individual['Year']==Year)&\n",
    "                                                            (temp_actual_bid_individual['Month']==Month)]    \n",
    "    \n",
    "    # Read the P0 data\n",
    "    temp_srmc_bid = pd.read_csv(f'{file_path}Lerner_Index/Regional_SRMC_Supply_Curve_{regionid}.csv',\n",
    "                            parse_dates=['SETTLEMENTDATE'],\n",
    "                            usecols=['SETTLEMENTDATE','REGIONID','RRP_simulated'])\\\n",
    "                    .rename(columns={'RRP_simulated':'P0'})\n",
    "    # Merge data\n",
    "    temp_actual_bid_individual = temp_actual_bid_individual.merge(right=temp_srmc_bid,\n",
    "                                                              on=['REGIONID','SETTLEMENTDATE'],\n",
    "                                                              how='left')\n",
    "    del temp_srmc_bid\n",
    "    \n",
    "    # Collect and rename column names\n",
    "    individual_columns = [column.split('_')[2] for column in temp_actual_bid_individual.columns if column.startswith('RRP_simulated') ]\n",
    "\n",
    "    for column in temp_actual_bid_individual.columns:\n",
    "        if column.startswith('RRP_simulated'):\n",
    "            temp_actual_bid_individual.rename(columns={column:column.split('_')[2]},inplace=True)\n",
    "            \n",
    "    # Convert from wide to long format\n",
    "    market_power_individual = pd.melt(temp_actual_bid_individual,\n",
    "                                      id_vars=['REGIONID','SETTLEMENTDATE',\n",
    "                                               'RegionalTarget','P0','P1'],\n",
    "                                      value_vars=individual_columns)\\\n",
    "                                .rename(columns={'variable':level,\n",
    "                                                 'value':'P1_alt'})\n",
    "    \n",
    "    # Calculate the un-adjusted individual market power\n",
    "    market_power_individual['MarketPower_Tentative_Ind'] = (market_power_individual['P1']-market_power_individual['P1_alt'])\\\n",
    "                                                                *market_power_individual['RegionalTarget']/12\n",
    "\n",
    "    # Merge with dispatch price\n",
    "    market_power_individual = market_power_individual.merge(temp_price,\n",
    "                                                            on=['REGIONID','SETTLEMENTDATE'],\n",
    "                                                            how='left').drop_duplicates()\n",
    "    \n",
    "    # Re-arrange the dataframe\n",
    "    market_power_individual = market_power_individual[['REGIONID','SETTLEMENTDATE','MARKETSUSPENDEDFLAG',level,\n",
    "                                                       'RegionalTarget','P0','P1_alt','P1','RRP',\n",
    "                                                       'MarketPower_Tentative_Ind']]\n",
    "    \n",
    "    # Merge with duid mapping\n",
    "    if level in ['DUID','STATIONNAME']:\n",
    "        market_power_individual = market_power_individual.merge(right=duid_mapping,\n",
    "                                                                on=[level],\n",
    "                                                                how='left')\n",
    "\n",
    "    # Filter data (dropping market suspended period)\n",
    "    market_power_individual = market_power_individual[market_power_individual['MARKETSUSPENDEDFLAG']==0]\n",
    "    \n",
    "    \n",
    "    # Put seasonality tags back\n",
    "    market_power_individual = market_power_individual.merge(right=temp_actual_bid_individual[['SETTLEMENTDATE','FY','Year','Quarter','Month','Hour']],\n",
    "                                                            on=['SETTLEMENTDATE'],\n",
    "                                                            how='left')\n",
    "    \n",
    "    # Aggregate the result\n",
    "    if level == 'STATIONNAME':\n",
    "        market_power_individual_agg = market_power_individual.groupby(by=['REGIONID','PARTICIPANTNAME','STATIONNAME','FUELTYPE',\n",
    "                                                                          'FY','Year','Quarter','Month','Hour'],\n",
    "                                                                      as_index=False)[['MarketPower_Tentative_Ind']].sum()\n",
    "    elif level == 'PARTICIPANTNAME':\n",
    "        market_power_individual_agg = market_power_individual.groupby(by=['REGIONID','PARTICIPANTNAME',\n",
    "                                                                          'FY','Year','Quarter','Month','Hour'],\n",
    "                                                                      as_index=False)[['MarketPower_Tentative_Ind']].sum()\n",
    "    \n",
    "    return market_power_individual_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad498b84",
   "metadata": {},
   "source": [
    "## Estimating station-level individual market power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9db97d",
   "metadata": {},
   "source": [
    "### Non-Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca60a751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T11:45:14.622609Z",
     "start_time": "2024-07-14T11:40:08.180617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2017 7\n",
      "Processing 2017 8\n",
      "Processing 2017 9\n",
      "Processing 2017 10\n",
      "Processing 2017 11\n",
      "Processing 2017 12\n",
      "Processing 2018 1\n",
      "Processing 2018 2\n",
      "Processing 2018 3\n",
      "Processing 2018 4\n",
      "Processing 2018 5\n",
      "Processing 2018 6\n",
      "Processing 2018 7\n",
      "Processing 2018 8\n",
      "Processing 2018 9\n",
      "Processing 2018 10\n",
      "Processing 2018 11\n",
      "Processing 2018 12\n",
      "Processing 2019 1\n",
      "Processing 2019 2\n",
      "Processing 2019 3\n",
      "Processing 2019 4\n",
      "Processing 2019 5\n",
      "Processing 2019 6\n",
      "Processing 2019 7\n",
      "Processing 2019 8\n",
      "Processing 2019 9\n",
      "Processing 2019 10\n",
      "Processing 2019 11\n",
      "Processing 2019 12\n",
      "Processing 2020 1\n",
      "Processing 2020 2\n",
      "Processing 2020 3\n",
      "Processing 2020 4\n",
      "Processing 2020 5\n",
      "Processing 2020 6\n",
      "Processing 2020 7\n",
      "Processing 2020 8\n",
      "Processing 2020 9\n",
      "Processing 2020 10\n",
      "Processing 2020 11\n",
      "Processing 2020 12\n",
      "Processing 2021 1\n",
      "Processing 2021 2\n",
      "Processing 2021 3\n",
      "Processing 2021 4\n",
      "Processing 2021 5\n",
      "Processing 2021 6\n",
      "Processing 2021 7\n",
      "Processing 2021 8\n",
      "Processing 2021 9\n",
      "Processing 2021 10\n",
      "Processing 2021 11\n",
      "Processing 2021 12\n",
      "Processing 2022 1\n",
      "Processing 2022 2\n",
      "Processing 2022 3\n",
      "Processing 2022 4\n",
      "Processing 2022 5\n",
      "Processing 2022 6\n",
      "Processing 2022 7\n",
      "Processing 2022 8\n",
      "Processing 2022 9\n",
      "Processing 2022 10\n",
      "Processing 2022 11\n",
      "Processing 2022 12\n",
      "Processing 2023 1\n",
      "Processing 2023 2\n",
      "Processing 2023 3\n",
      "Processing 2023 4\n",
      "Processing 2023 5\n",
      "Processing 2023 6\n",
      "SA1 Done.\n"
     ]
    }
   ],
   "source": [
    "level = 'STATIONNAME'\n",
    "for regionid in ['SA1']:\n",
    "    market_power_individual = pd.DataFrame()\n",
    "    \n",
    "    for Year in range(2017,2024):\n",
    "        if Year == 2017:\n",
    "            for Month in range(7,13):\n",
    "                print(f'Processing {Year} {Month}')\n",
    "                temp_market_power_individual =read_and_process_individual_market_power(file_path,dispatch_price_path,regionid,level,Year,Month)\n",
    "                market_power_individual = pd.concat([market_power_individual,temp_market_power_individual])\n",
    "\n",
    "        elif Year == 2023:\n",
    "            for Month in range(1,7):\n",
    "                print(f'Processing {Year} {Month}')\n",
    "                temp_market_power_individual =read_and_process_individual_market_power(file_path,dispatch_price_path,regionid,level,Year,Month)\n",
    "                market_power_individual = pd.concat([market_power_individual,temp_market_power_individual])\n",
    "        else:\n",
    "            for Month in range(1,13):\n",
    "                print(f'Processing {Year} {Month}')\n",
    "                temp_market_power_individual =read_and_process_individual_market_power(file_path,dispatch_price_path,regionid,level,Year,Month)\n",
    "                market_power_individual = pd.concat([market_power_individual,temp_market_power_individual])\n",
    "                \n",
    "    market_power_individual.to_csv(f'/Volumes/EnergyData/AER/Lerner_Index/Regional_individual_market_power_{regionid}_{level}.csv',\n",
    "                                   index=False)\n",
    "    print(regionid,'Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49f9d7",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2825db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T01:42:58.818736Z",
     "start_time": "2024-07-23T01:42:58.800371Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Need to add FY columns, need access to the FYYearMonth data stored in T5.\n",
    "\"\"\"\n",
    "def read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days):\n",
    "    # Read the DUID level data\n",
    "    temp_df = pd.read_csv(f'{file_path}/Lerner_Index/P1_alt/Storage/{storage_type}/Regional_ACTUAL_Supply_Curve_{regionid}_{level}_{storage_type}_{window_days}_alt.csv',\n",
    "                          parse_dates=['SETTLEMENTDATE'])\\\n",
    "                .drop(columns=['TOTALDEMAND','NETINTERCHANGE','FIXEDLOAD','DISPATCHABLELOAD'])\\\n",
    "                .rename(columns={'RRP_simulated':'P1'})\n",
    "    # Collect and rename column names\n",
    "    individual_columns = [column.split('_')[2] for column in temp_df.columns if column.startswith('RRP_simulated') ]\n",
    "\n",
    "    if len(individual_columns) > 0:\n",
    "        for column in temp_df.columns:\n",
    "            if column.startswith('RRP_simulated'):\n",
    "                temp_df.rename(columns={column:column.split('_')[2]},inplace=True)\n",
    "\n",
    "        # Convert from wide to long format\n",
    "        market_power_individual = pd.melt(temp_df,\n",
    "                                        id_vars=['REGIONID','SETTLEMENTDATE',\n",
    "                                                'RegionalTarget','P1'],\n",
    "                                        value_vars=individual_columns)\\\n",
    "                                    .rename(columns={'variable':level,\n",
    "                                                    'value':'P1_alt'})\n",
    "        market_power_individual['Year'] = market_power_individual['SETTLEMENTDATE'].parallel_apply(lambda x: (x-datetime.timedelta(minutes=5)).year)\n",
    "        market_power_individual['Month'] = market_power_individual['SETTLEMENTDATE'].parallel_apply(lambda x: (x-datetime.timedelta(minutes=5)).month)\n",
    "        market_power_individual['FY'] = market_power_individual.parallel_apply(lambda row: YearMonthFY[(row['Year'],row['Month'])],axis=1)\n",
    "        market_power_individual['Quarter'] = market_power_individual['Month'].parallel_apply(lambda x: 'Q'+str(math.ceil(x/3)))\n",
    "        market_power_individual['Hour'] = market_power_individual['SETTLEMENTDATE'].parallel_apply(lambda x: (x-datetime.timedelta(minutes=5)).hour)\n",
    "        \n",
    "        # Calculate the un-adjusted individual market power\n",
    "        market_power_individual['Cost_P1'] = (market_power_individual['P1']*market_power_individual['RegionalTarget'])/12\n",
    "        market_power_individual['Cost_P1_alt'] = (market_power_individual['P1_alt']*market_power_individual['RegionalTarget'])/12\n",
    "\n",
    "        market_power_individual['MarketPower_Tentative_Ind'] = market_power_individual['Cost_P1']-market_power_individual['Cost_P1_alt']\n",
    "\n",
    "        market_power_individual_agg = market_power_individual\\\n",
    "                        .groupby(by=['REGIONID',level,'FY','Year','Quarter','Month','Hour'],as_index=False)\\\n",
    "                        [['Cost_P1','Cost_P1_alt','MarketPower_Tentative_Ind']].sum()\n",
    "        return market_power_individual_agg\n",
    "    else:\n",
    "        market_power_individual_agg = pd.DataFrame(columns=['REGIONID',level,'FY','Year','Quarter','Month','Hour',\n",
    "                                                            'Cost_P1','Cost_P1_alt','MarketPower_Tentative_Ind'])\n",
    "        return market_power_individual_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10265218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery\n",
    "storage_type = 'Battery'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [1,3,5]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5704c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydro_pumped\n",
    "storage_type = 'Hydro_pumped'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [7,14,21,28]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cdf2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydro_gas\n",
    "storage_type = 'Hydro_gas'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [0]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098f418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydro_gravity\n",
    "storage_type = 'Hydro_gravity'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [0]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1273f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydro_gas\n",
    "storage_type = 'Hydro_gas'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [99]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8968d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydro_river\n",
    "storage_type = 'Hydro_river'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [0]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0daa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Need to add FY columns, need access to the FYYearMonth data stored in T5.\n",
    "\"\"\"\n",
    "def read_and_process_individual_market_power_storage_vwadp(file_path,YearMonthFY,regionid,storage_type,level,window_days):\n",
    "    # Read the DUID level data\n",
    "    temp_df = pd.read_csv(f'{file_path}/Lerner_Index/P1_alt/Storage/{storage_type}/Regional_ACTUAL_Supply_Curve_{regionid}_{level}_{storage_type}_{window_days}_alt_vwadp.csv',\n",
    "                          parse_dates=['SETTLEMENTDATE'])\\\n",
    "                .drop(columns=['TOTALDEMAND','NETINTERCHANGE','FIXEDLOAD','DISPATCHABLELOAD'])\\\n",
    "                .rename(columns={'RRP_simulated':'P1'})\n",
    "    # Collect and rename column names\n",
    "    individual_columns = [column.split('_')[2] for column in temp_df.columns if column.startswith('RRP_simulated') ]\n",
    "\n",
    "    if len(individual_columns) > 0:\n",
    "        for column in temp_df.columns:\n",
    "            if column.startswith('RRP_simulated'):\n",
    "                temp_df.rename(columns={column:column.split('_')[2]},inplace=True)\n",
    "\n",
    "        # Convert from wide to long format\n",
    "        market_power_individual = pd.melt(temp_df,\n",
    "                                        id_vars=['REGIONID','SETTLEMENTDATE',\n",
    "                                                'RegionalTarget','P1'],\n",
    "                                        value_vars=individual_columns)\\\n",
    "                                    .rename(columns={'variable':level,\n",
    "                                                    'value':'P1_alt'})\n",
    "        market_power_individual['Year'] = market_power_individual['SETTLEMENTDATE'].parallel_apply(lambda x: (x-datetime.timedelta(minutes=5)).year)\n",
    "        market_power_individual['Month'] = market_power_individual['SETTLEMENTDATE'].parallel_apply(lambda x: (x-datetime.timedelta(minutes=5)).month)\n",
    "        market_power_individual['FY'] = market_power_individual.parallel_apply(lambda row: YearMonthFY[(row['Year'],row['Month'])],axis=1)\n",
    "        market_power_individual['Quarter'] = market_power_individual['Month'].parallel_apply(lambda x: 'Q'+str(math.ceil(x/3)))\n",
    "        market_power_individual['Hour'] = market_power_individual['SETTLEMENTDATE'].parallel_apply(lambda x: (x-datetime.timedelta(minutes=5)).hour)\n",
    "        \n",
    "        # Calculate the un-adjusted individual market power\n",
    "        market_power_individual['Cost_P1'] = (market_power_individual['P1']*market_power_individual['RegionalTarget'])/12\n",
    "        market_power_individual['Cost_P1_alt'] = (market_power_individual['P1_alt']*market_power_individual['RegionalTarget'])/12\n",
    "\n",
    "        market_power_individual['MarketPower_Tentative_Ind'] = market_power_individual['Cost_P1']-market_power_individual['Cost_P1_alt']\n",
    "\n",
    "        market_power_individual_agg = market_power_individual\\\n",
    "                        .groupby(by=['REGIONID',level,'FY','Year','Quarter','Month','Hour'],as_index=False)\\\n",
    "                        [['Cost_P1','Cost_P1_alt','MarketPower_Tentative_Ind']].sum()\n",
    "        return market_power_individual_agg\n",
    "    else:\n",
    "        market_power_individual_agg = pd.DataFrame(columns=['REGIONID',level,'FY','Year','Quarter','Month','Hour',\n",
    "                                                            'Cost_P1','Cost_P1_alt','MarketPower_Tentative_Ind'])\n",
    "        return market_power_individual_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e9ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery\n",
    "storage_type = 'Battery'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [1,3,5]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage_vwadp(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}_vwadp.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e41085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydro_all\n",
    "storage_type = 'Hydro_all'\n",
    "regionids = ['NSW1','SA1','QLD1','VIC1']\n",
    "window_days_list = [7,14,21,28]\n",
    "level = 'STATIONNAME'\n",
    "for regionid in regionids:\n",
    "    for window_days in window_days_list:\n",
    "        read_and_process_individual_market_power_storage_vwadp(file_path,YearMonthFY,regionid,storage_type,level,window_days)\\\n",
    "            .to_csv(f'{file_path}/Lerner_Index/Aggregated_Results/Individual/Storage/{storage_type}/Regional_individual_market_power_{regionid}_{level}_{storage_type}_{window_days}_vwadp.csv',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e65d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
